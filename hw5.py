from pathlib import Path
import numpy as np
import pandas as pd
import json

class QuestionnaireAnalysis:
    """
    Reads and analyzes data generated by the questionnaire experiment.
    Should be able to accept strings and pathlib.Path objects.
    """

    def __init__(self, data_fname):
        self.data_fname = Path(data_fname)

        if self.data_fname.exists()==False:
            raise ValueError('file does not exist')

    def read_data(self):
        """Reads the json data located in self.data_fname into memory, to
        the attribute self.data.
        """
        if self.data_fname.exists():
            with open(self.data_fname) as data_file:
                data = json.load(data_file)
        self.data = pd.DataFrame(data)
        
        return self.data


    '''
    The following questions should be answered by writing additional method(s) that perform the 
    needed computation. The tests load the ground truth from the repo and check that your 
    resulting values are identical to it.

    1. Plot the distribution of ages of the participants. 
    The bins for the histogram should be [0, 10), [10, 20), [20, 30), ..., [90, 100]. 
    The function should return the result.
    '''
    #run through ages in file, extract all ages, create histogram
    def extract_column(self, column_name: str):
        df = self.read_data()
        curr_column = df[column_name].replace('nan',np.NaN)

        return curr_column

    def show_age_distrib(self):
        """Calculates and plots the age distribution of the participants.

	Returns
	-------
	hist : np.ndarray
	  Number of people in a given bin
	bins : np.ndarray
	  Bin edges
        """
        ages = self.extract_column('age')
        ages = ages.dropna().to_numpy()
        distrib = np.histogram(ages,bins=10,range=(0,100))

        return distrib

    '''
    2. Participants without a valid email are useless since we can't contact them. 
    Remove all of the rows with an invalid address and return the new DataFrame.
    '''

    def remove_rows_without_mail(self) -> pd.DataFrame:
        """Checks self.data for rows with invalid emails, and removes them.

	Returns
	-------
	df : pd.DataFrame
	  A corrected DataFrame, i.e. the same table but with the erroneous rows removed and
	  the (ordinal) index after a reset.
        """
    #check whether email address contains @ and . at the right spot
        df = self.read_data()
        delimited = df['email'].str.split('@',expand = True).rename(columns={0:'username',1:'domain'})
        suffix = delimited['domain'].str.split('.',expand = True).rename(columns={0:'domain',1:'suffix'})
        delimited['domain'], delimited['suffix'] = suffix['domain'], suffix['suffix']
        valid = delimited[(delimited['username'].str.isalnum()) & (delimited['domain'].str.isalnum()) & (delimited['suffix'].str.isalnum())]

        remove_rows = df.drop(df.index[valid.index.values])
        df = df.drop(df.index[remove_rows.index.values]).reset_index(drop=True)

        return df
    
    '''
    3. Some participants haven't answered all of the question. 
    It was decided that the grade for those missing questions will be the average grade of 
    the other question for that subject. Write a method that works on the original DataFrame 
    (in `self.data`), replaces the missing values with the mean for that subject in the other 
    questions and returns the corrected DataFrame as well as a `np.array` of the indices of 
    the rows that were corrected.
    '''

    def fill_na_with_mean(self):
        """Finds, in the original DataFrame, the subjects that didn't answer
        all questions, and replaces that missing value with the mean of the
        other grades for that student.

	Returns
	-------
	df : pd.DataFrame
	  The corrected DataFrame after insertion of the mean grade
	arr : np.ndarray
          Row indices of the students that their new grades were generated
        """

        #find missing answers in q1-5
        all_questions = self.extract_column(['q1','q2','q3','q4','q5'])
        idx =  pd.isnull(all_questions).any(1)
        #create an array with indices of generated grades
        generated_grades = idx.index[idx==True].to_numpy()

        #calculate average for existing questions
        for grade in generated_grades:
            average = all_questions.iloc[grade].mean(axis=0)
            all_questions.iloc[grade].fillna(average,inplace=True)
        
        df = self.read_data()
        cols_to_change = ['q1','q2','q3','q4','q5']
        df[cols_to_change] = all_questions

        return df, generated_grades
    
    '''
        4. Each participants should receive an integer score for his or her answers, 
        given in a new "score" column you should add. After some deliberation it was decided 
        that if a subject has no grade in two questions or more, the score of that subject 
        will be NA. Write a method that produces this score by averaging the grades of the 
        not-NaN questions in the relevant rows.
    '''

    def score_subjects(self, maximal_nans_per_sub: int = 1) -> pd.DataFrame:
        """Calculates the average score of a subject and adds a new "score" column
        with it.

        If the subject has more than "maximal_nans_per_sub" NaN in his grades, the
        score should be NA. Otherwise, the score is simply the mean of the other grades.
        The datatype of score is UInt8, and the floating point raw numbers should be
        rounded down.

        Parameters
        ----------
        maximal_nans_per_sub : int, optional
            Number of allowed NaNs per subject before giving a NA score.

        Returns
        -------
        pd.DataFrame
            A new DF with a new column - "score".
        """

        #for columns q1-5, check whether there are more than limit nan
        sub_grades = self.extract_column(['q1','q2','q3','q4','q5'])
        num_of_nans = sub_grades.isnull().sum(axis=1)
        removed_subs = num_of_nans[num_of_nans>maximal_nans_per_sub].index.tolist()

        #if so, set grade to NA; else calculate mean average
        for sub in sub_grades.index:
            if sub in removed_subs:
                sub_grades.loc[sub, 'score'] = np.NaN
            else:
                sub_grades.loc[sub, 'score'] = sub_grades.loc[sub].mean(axis=0)
        
        sub_grades['score'] = np.floor(sub_grades['score']).astype('UInt8')

        #add a new column to dataframe
        df = self.read_data()
        df['score'] = sub_grades['score']
        
        return df

    '''
        5. **BONUS 15 POINTS** There's reason to believe that there's a correlation between 
        the subject's gender, age and grades.

    a. Use the original DataFrame and transform its index into a MultiIndex with three levels: 
    the ordinal index (row number), gender and age.

    b. Allocate the different subjects into groups based on two parameters: Their gender, 
    and whether their age is above or below 40. Hint - use `df.groupby`. 
    The result should be similar to what is shown in the figure below 
    (you don't have to plot it yourself).

    c. Return the DataFrame containing the average result per question per group.
    '''

    def correlate_gender_age(self) -> pd.DataFrame:
        """Looks for a correlation between the gender of the subject, their age
        and the score for all five questions.

	Returns
	-------
	pd.DataFrame
        A DataFrame with a MultiIndex containing the gender and whether the subject is above
	    40 years of age, and the average score in each of the five questions.
    """
    #create multiindex -> index, gender, age
    #transform age to true or false (above 40 or not)
    #group by gender and age
    #check average score per group
        q_cols = ['q1','q2','q3','q4','q5']
        df = self.read_data()
        df[q_cols] = self.extract_column(q_cols)
        df['age'] = self.extract_column('age')
        df['age'] = df['age'].fillna(df['age'].mean())
        df['age'] = df['age'] > 40
        df = df.groupby(['gender','age'])[q_cols].mean().reset_index()
        df = df.set_index([df.index,'gender','age'])

        return df

    