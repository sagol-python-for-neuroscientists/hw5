from typing import Union, Tuple
import pathlib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt



class QuestionnaireAnalysis:
    """
    Reads and analyzes data generated by the questionnaire experiment.
    Should be able to accept strings and pathlib.Path objects.
    """

    def __init__(self, data_fname: Union[pathlib.Path, str]):
        self.data_fname = pathlib.Path(data_fname)
        self.data = [] #just to mark it should be here
        if not(self.data_fname.exists()):
            raise ValueError('Path does not exist')
        #self.read_data()

    def read_data(self):
        """Reads the json data located in self.data_fname into memory, to
        the attribute self.data.
        """
        # read data
        self.data = pd.read_json(self.data_fname)

        # force things to be strings
        self.data[['email','first_name','last_name','gender']] = self.data[['email','first_name','last_name','gender']].astype("string")

    def show_age_distrib(self) -> Tuple[np.ndarray, np.ndarray]:
        """Calculates and plots the age distribution of the participants.

        Returns
        -------
        hist : np.ndarray
        Number of people in a given bin
        bins : np.ndarray
        Bin edges
        """
        # get series
        relv_ser = self.data['age']

        # calculate hist
        data_bins = range(0,110,10)
        hist, bins = np.histogram(relv_ser,bins=data_bins)

        # plot it
        plt.stairs(hist, bins)
        return hist, bins

    def remove_rows_without_mail(self) -> pd.DataFrame:
        """Checks self.data for rows with invalid emails, and removes them.

        Returns
        -------
        df : pd.DataFrame
        A corrected DataFrame, i.e. the same table but with the erroneous rows removed and
        the (ordinal) index after a reset.
        """

        # collect conditions
        end_OK = self.data['email'].str.endswith(('@','.'))
        start_OK = self.data['email'].str.startswith(('@','.'))
        not_follow = self.data['email'].str.contains(r'@\.')
        contain_at = self.data['email'].str.contains('[@]')
        contain_dot = self.data['email'].str.contains(r'[\.]')
        no_more_once = self.data['email'].str.replace('@','',n=1).str.contains('@') # remove 1 '@'. if still contains, it has more than 1 '@'

        # filter table
        df = self.data[(~end_OK) & (~start_OK) & (~not_follow) & contain_at & contain_dot & (~no_more_once)]

        # fix table to match check
        df[['email','first_name','last_name','gender']] = df[['email','first_name','last_name','gender']].astype("object")
        df.reset_index(drop=True,inplace=True)
        return df

    def fill_na_with_mean(self) -> Tuple[pd.DataFrame, np.ndarray]:
        """Finds, in the original DataFrame, the subjects that didn't answer
        all questions, and replaces that missing value with the mean of the
        other grades for that student.

        Returns
        -------
        df : pd.DataFrame
        The corrected DataFrame after insertion of the mean grade
        arr : np.ndarray
        Row indices of the students that their new grades were generated
        """
        q_cols = ["q1","q2","q3","q4","q5"]
        nan_answers = self.data[q_cols].isnull()
        arr = nan_answers.any(axis=1).to_numpy().nonzero()[0] # find rows where at least 1 question is empty

        df = self.data[q_cols].T.fillna(self.data[q_cols].mean(axis=1)).T # taken from https://stackoverflow.com/questions/33058590/pandas-dataframe-replacing-nan-with-row-average
        # df = self.data[q_cols].fillna(self.data[q_cols].mean(axis=1),axis=1) # what I would have done if it was implamented. The problem here is the mismatch between number of replacing, compared to number of replaced
        return df, arr
    
    def score_subjects(self, maximal_nans_per_sub: int = 1) -> pd.DataFrame:
        """Calculates the average score of a subject and adds a new "score" column
        with it.

        If the subject has more than "maximal_nans_per_sub" NaN in his grades, the
        score should be NA. Otherwise, the score is simply the mean of the other grades.
        The datatype of score is UInt8, and the floating point raw numbers should be
        rounded down.

        Parameters
        ----------
        maximal_nans_per_sub : int, optional
            Number of allowed NaNs per subject before giving a NA score.

        Returns
        -------
        pd.DataFrame
            A new DF with a new column - "score".
        """
        
        q_cols = ["q1","q2","q3","q4","q5"]

        # add "score" col, with mean of 5 questions
        mean_vals = self.data[q_cols].mean(axis=1).apply(np.floor).astype("UInt8")

        # count nan per row, find rows with too match nans
        too_nany = self.data[q_cols].isnull().sum(axis=1) > maximal_nans_per_sub

        # place nan in too nany rows
        mean_vals[too_nany] = np.nan

        df = self.data
        df["score"] = mean_vals
        return df
    
    def correlate_gender_age(self) -> pd.DataFrame:
        """Looks for a correlation between the gender of the subject, their age
        and the score for all five questions.

        Returns
        -------
        pd.DataFrame
            A DataFrame with a MultiIndex containing the gender and whether the subject is above
            40 years of age, and the average score in each of the five questions.
        """

        # get copy of relevant cols, convert "gender" back to obj for test
        df = self.data[["gender","age","q1","q2","q3","q4","q5"]]
        df['gender'] = df['gender'].astype("object")

        # convert age to higher than 40 = True
        df["age"] = df.age > 40

        # create MultiIndex (Note - keeping the original index is not doing anything)
        df.set_index(['gender','age'], append=True)

        # Group by gender than age, and mean
        grouped = df.groupby(['gender','age'])
        corr_res = grouped.mean()
        return corr_res